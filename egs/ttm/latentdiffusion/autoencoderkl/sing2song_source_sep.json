{
        // amphion-related
        "model_type": "AutoencoderKL",
        "task_type": "ttm",
        // Specify the output root path to save model ckpts and logs
        "log_dir": "/nvme/data/zja/diffusion/ckpts",
        "dataset": [
                "chinese_short",
                "english_short"
        ],
        "dataset_path": {
                // TODO: Fill in your dataset path
                // "musiccaps": "/home/wangyuancheng.p/zja/music/MusicCaps",
                // "msd": "/mnt/data2/zhangxueyao/million-song-dataset",
        },
        "use_custom_dataset": [],
        "preprocess": {
                // Specify the output root path to save the processed data 
                "processed_dir": "/nvme/data/zja/netease/dataset",
                // Audio / FFT info
                "sample_rate": 16000,
                "audio_channels": 1,
                "segment_duration": 10,
                "extract_mel": true,
                "extract_acoustic_token": false,
                "extract_linear_spec": false,
                "n_mel": 80,
                "n_fft": 1024,
                "win_size": 1024,
                "hop_size": 256,
                "fmin": 0,
                "fmax": 8000,
                "use_caption": false,
                "use_ref_wav": false,
                "use_mel": true,
                "mel_dir": "mel",
                "train_file": "train.json",
                "valid_file": "test.json",
        },
        "model": {
                "autoencoderkl": {
                        "ch": 128,
                        "ch_mult": [
                                1,
                                1,
                                2,
                                2,
                                4
                        ],
                        "num_res_blocks": 2,
                        "in_channels": 1,
                        "z_channels": 4,
                        "out_ch": 1,
                        "double_z": true
                },
                "loss": {
                        "kl_weight": 1e-8,
                        "disc_weight": 0.5,
                        "disc_factor": 1.0,
                        "logvar_init": 0.0,
                        "min_adapt_d_weight": 0.0,
                        "max_adapt_d_weight": 10.0,
                        "disc_start": 5000,
                        "disc_in_channels": 1,
                        "disc_num_layers": 3,
                        "use_actnorm": false
                },
                "vocoder_config_path": "/nvme/data/zja/diffusion/pretrained/vocoder/config.json",
                "vocoder_path": "/nvme/data/zja/diffusion/pretrained/vocoder/g_01250000"
        },
        "train": {
                "use_audiocraft_dataset": false,
                // -1 means no limit
                "train_num_samples": -1,
                // -1 means no limit
                "valid_num_samples": 20,
                "batch_size": 8,
                "gradient_accumulation_step": 1,
                "tracker": [
                        "tensorboard"
                ],
                "random_seed": 970227,
                // -1 means no limit
                "max_epoch": -1,
                // for step-based checkpoint
                "save_checkpoint_stride_step": [
                        100,
                ],
                "keep_last_step": [
                        1,
                ],
                "save_checkpoint_stride": [
                        1,
                ],
                // unit is epoch
                "keep_last": [
                        1,
                ],
                // -1 means infinite, if one number will broadcast
                "run_eval": [
                        false,
                        true
                ],
                // TODO: EMA
                "optimizer": "AdamW",
                "adam": {
                        "lr": 1e-4,
                        "betas": [
                                0.9,
                                0.95,
                        ],
                },
                "scheduler": null,
        },
        "inference": {
                "batch_size": 1,
        },
}