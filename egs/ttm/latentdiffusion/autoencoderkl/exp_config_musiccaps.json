{
        // amphion-related
        "model_type": "AutoencoderKL",
        "task_type": "ttm",
        // Specify the output root path to save model ckpts and logs
        "log_dir": "ckpts/ttm",
        "dataset": [
                "musiccaps"
        ],
        "dataset_path": {
                // TODO: Fill in your dataset path
                "musiccaps": "/home/wangyuancheng.p/zja/music/MusicCaps",
                // "musdb18": "/nvme/amphion/zhfang/zja/_dataset/musdb18",
        },
        "use_custom_dataset": [],
        "preprocess": {
                // Specify the output root path to save the processed data 
                "processed_dir": "data",
                // Audio / FFT info
                "sample_rate": 16000,
                "audio_channels": 1,
                "segment_duration": 10,
                "extract_mel": true,
                "extract_acoustic_token": false,
                "extract_linear_spec": false,
                "n_mel": 80,
                "n_fft": 1024,
                "win_size": 1024,
                "hop_size": 256,
                "fmin": 0,
                "fmax": 8000,
                "use_caption": true,
                "use_ref_wav": false,
                "use_mel": true,
                "mel_dir": "mel",
                "train_file": "train.json",
                "valid_file": "test.json",
        },
        "model": {
                "autoencoderkl": {
                        "ch": 128,
                        "ch_mult": [
                                1,
                                1,
                                2,
                                2,
                                4
                        ],
                        "num_res_blocks": 2,
                        "in_channels": 1,
                        "z_channels": 4,
                        "out_ch": 1,
                        "double_z": true
                },
                "loss": {
                        "kl_weight": 1e-8,
                        "disc_weight": 0.5,
                        "disc_factor": 1.0,
                        "logvar_init": 0.0,
                        "min_adapt_d_weight": 0.0,
                        "max_adapt_d_weight": 10.0,
                        "disc_start": 10001,
                        "disc_in_channels": 1,
                        "disc_num_layers": 3,
                        "use_actnorm": false
                }
        },
        "train": {
                "use_audiocraft_dataset": false,
                // -1 means no limit
                "train_num_samples": -1,
                // -1 means no limit
                "valid_num_samples": 20,
                "batch_size": 4,
                "gradient_accumulation_step": 1,
                "tracker": [
                        "tensorboard"
                ],
                "random_seed": 970227,
                // -1 means no limit
                "max_epoch": -1,
                "save_checkpoint_stride": [
                        2,
                        20
                ],
                // unit is epoch
                "keep_last": [
                        1,
                        1
                ],
                // -1 means infinite, if one number will broadcast
                "run_eval": [
                        false,
                        true
                ],
                // TODO: EMA
                "optimizer": "Adam",
                "adam": {
                        "lr": 1e-4,
                        "betas": [
                                0.9,
                                0.95,
                        ],
                },
                "scheduler": "cosine",
                "warmup_steps": 500,
                "total_training_steps": 1000000,
                "grad_clip_thresh": 1.0,
                "ddp": false,
        },
        "inference": {
                "batch_size": 1,
        },
}