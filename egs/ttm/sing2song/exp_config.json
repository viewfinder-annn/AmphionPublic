{
        // amphion-related
        "model_type": "Sing2Song",
        "task_type": "ttm",
        // Specify the output root path to save model ckpts and logs
        "log_dir": "ckpts/ttm",
        "dataset": [
                "musdb18"
        ],
        "dataset_path": {
                // TODO: Fill in your dataset path
                // "musiccaps": "/home/wangyuancheng.p/zja/music/MusicCaps",
                "musdb18": "/nvme/amphion/zhfang/zja/_dataset/musdb18",
        },
        "use_custom_dataset": [],
        "preprocess": {
                // Specify the output root path to save the processed data 
                "processed_dir": "/nvme/amphion/zhfang/zja/_datase_utils/preprocessor",

                // Audio / FFT info
                "sample_rate": 32000,
                "audio_channels": 1,
                "segment_duration": 10,

                "n_mel": 512,
                "n_fft": 2048,
                "win_size": 2048,
                "hop_size": 512,
                "fmin": 0,
                "fmax": 16000,

                // "use_caption": true,
                "use_ref_wav": true,

                "train_file": "train.json",
                "valid_file": "test.json",
        },
        "train": {
                "ddp": true,
                "use_audiocraft_dataset": false,
                // -1 means no limit
                "train_num_samples": 100,
                // -1 means no limit
                "valid_num_samples": 20,
                "batch_size": 8,
                "gradient_accumulation_step": 1,
                "tracker": [
                        "tensorboard"
                ],
                "random_seed": 970227,
                // -1 means no limit
                "max_epoch": -1,
                "save_checkpoint_stride": [
                        1,
                        5
                ],
                // unit is epoch
                "keep_last": [
                        1,
                        1
                ],
                // -1 means infinite, if one number will broadcast
                "run_eval": [
                        false,
                        true
                ],
                // TODO: EMA
                "optimizer": "AdamW",
                "adamw": {
                        "lr": 1e-4,
                        "betas": [
                                0.9,
                                0.95,
                        ],
                },
                "scheduler": "cosine",
                "warmup_steps": 20,
                "total_training_steps": 1000000,
                "grad_clip_thresh": 1.0,
        },
        "inference": {
                "batch_size": 1,
        },
        // original
        "audiocraft": {
                "device": "cuda",
                "dtype": "float32",
                "autocast": false,
                "autocast_dtype": "float16",
                "seed": 10086,
                "show": false,
                "continue_from": null,
                "execute_only": null,
                "execute_inplace": false,
                // "benchmark_no_load": false,
                "efficient_attention_backend": "torch",
                "fsdp": {
                        "use": false,
                        "param_dtype": "float16",
                        "reduce_dtype": "float32",
                        "buffer_dtype": "float32",
                        "sharding_strategy": "shard_grad_op",
                        "per_block": true
                },
                "dataset": {
                        "batch_size": 4,
                        "num_workers": 1,
                        "segment_duration": 10,
                        "num_samples": null,
                        "return_info": true,
                        "shuffle": false,
                        "sample_on_duration": false,
                        "sample_on_weight": false,
                        "min_segment_ratio": 0.8,
                        "train": {
                                "num_samples": 8,
                                "shuffle": false,
                                "shuffle_seed": 10086,
                                "permutation_on_files": false,
                                "merge_text_p": 0,
                                "drop_desc_p": 0,
                                "drop_other_p": 0
                        },
                        "valid": {
                                "num_samples": 8
                        },
                        "evaluate": {
                                "num_samples": 10000
                        },
                        "generate": {
                                "num_samples": 50,
                                "return_info": true
                        }
                },
                "classifier_free_guidance": {
                        "training_dropout": 0.05,
                        "inference_coef": 3.0
                },
                "attribute_dropout": {},
                "fuser": {
                        "cross_attention_pos_emb": false,
                        "cross_attention_pos_emb_scale": 1,
                        "sum": [],
                        "prepend": [],
                        "cross": [
                                "action", "category"
                        ],
                        "input_interpolate": []
                },
                "conditioners": {
                        "action": {
                                "model": "category",
                                "category": {
                                        // num_actions + 1(null condition)
                                        "n_bins": 4,
                                        "dim": 512,
                                }
                        },
                        "category": {
                                "model": "category",
                                "category": {
                                        // num_categories + 1(null condition)
                                        "n_bins": 5,
                                        "dim": 512,
                                }
                        },
                },
                "sample_rate": 32000,
                "channels": 1,
                "compression_model_checkpoint": "//pretrained/facebook/encodec_32khz",
                "compression_model_n_q": null,
                "tokens": {
                        "padding_with_special_token": false
                },
                "interleave_stereo_codebooks": {
                        "use": false,
                        "per_timestep": false
                },
                "lm_model": "transformer_lm",
                "codebooks_pattern": {
                        "modeling": "delay",
                        "delay": {
                                "delays": [
                                        0,
                                        1,
                                        2,
                                        3
                                ],
                                "flatten_first": 0,
                                "empty_initial": 0
                        },
                        "unroll": {
                                "flattening": [
                                        0,
                                        1,
                                        2,
                                        3
                                ],
                                "delays": [
                                        0,
                                        0,
                                        0,
                                        0
                                ]
                        },
                        "music_lm": {
                                "group_by": 2
                        },
                        "coarse_first": {
                                "delays": [
                                        0,
                                        0,
                                        0
                                ]
                        }
                },
                "transformer_lm": {
                        "dim": 1024,
                        "num_heads": 16,
                        "num_layers": 24,
                        "hidden_scale": 4,
                        "n_q": 4,
                        "card": 2048,
                        "dropout": 0.0,
                        "emb_lr": null,
                        "activation": "gelu",
                        "norm_first": true,
                        "bias_ff": false,
                        "bias_attn": false,
                        "bias_proj": false,
                        "past_context": null,
                        "causal": true,
                        "custom": false,
                        "memory_efficient": true,
                        "attention_as_float32": false,
                        "layer_scale": null,
                        "positional_embedding": "sin",
                        "xpos": false,
                        "checkpointing": "none",
                        "weight_init": "gaussian",
                        "depthwise_init": "current",
                        "zero_bias_init": true,
                        "norm": "layer_norm",
                        "cross_attention": false,
                        "qk_layer_norm": false,
                        "qk_layer_norm_cross": false,
                        "attention_dropout": null,
                        "kv_repeat": 1,
                        "two_step_cfg": false
                }
        }
}